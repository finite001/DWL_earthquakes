{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1270f0f8-9022-46ae-ae35-26624b2df0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226ad16-aabb-4b0e-9afc-95d7371cc426",
   "metadata": {},
   "source": [
    "### Connection to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a0cb0f-5ad5-4bcf-8acf-87ad5ab842e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the connection details for the rds db from .env file\n",
    "config = dotenv_values(\".env\")  \n",
    "HOST_RDS = config['HOST_RDS']\n",
    "DBNAME_RDS = config['DBNAME_RDS']\n",
    "USER_RDS = config['USER_RDS']\n",
    "PASSWORD_RDS = config['PASSWORD_RDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48be2f06-0c64-4a3f-a4df-8aa5e742a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from postgreSQL tables\n",
    "engine_str = 'postgresql+psycopg2://' + USER_RDS + ':' + PASSWORD_RDS + \"@\" + HOST_RDS + \":5432/dbeq\"\n",
    "engine = create_engine(engine_str)\n",
    "dbConnection = engine.connect()\n",
    "twitter = pd.read_sql(\"SELECT * FROM dl_twitter\", dbConnection)\n",
    "users = pd.read_sql(\"SELECT * from dl_twitterusers\", dbConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bb0dc88-0f84-4d37-8c47-e1da83d89ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, author_id, id, created_at]\n",
      "Index: []\n",
      "                          id         username                          name  \\\n",
      "11                       246           blaine               Blaine Cook 💉💉🎉   \n",
      "823                   615403       avalonstar  Bryan Veloso 🌟 Forging Ahead   \n",
      "873                   630163          superic                 Eric Willis 🦃   \n",
      "886                   634703            k3nnr                     k3nnr.ogg   \n",
      "889                   635463    FauziKHamadeh              Fauzi K. Hamadeh   \n",
      "...                      ...              ...                           ...   \n",
      "2501742  1406414300311212034   yourlight51129      🌟🌙 🥚let's shine together   \n",
      "2501794  1406530652841852934        NewsBits_                     News Bits   \n",
      "2502333  1407964313793425411  viral48official                       viral48   \n",
      "2505737  1417005186262867973        MNSTAPLZA                   I MISS BTS.   \n",
      "2507964  1422990264147185666  NewsFromBehind1              News From Behind   \n",
      "\n",
      "                              location  \n",
      "11                          Nelson, BC  \n",
      "823           Silver Lake, Los Angeles  \n",
      "873                       Pacifica, CA  \n",
      "886                           Bay Area  \n",
      "889                      San Mateo, CA  \n",
      "...                                ...  \n",
      "2501742       Republik der Philippinen  \n",
      "2501794   Vereinigte Arabische Emirate  \n",
      "2502333               Bengaluru, India  \n",
      "2505737  him/her | 20 | bi | genderfld  \n",
      "2507964                  कोलकाता, भारत  \n",
      "\n",
      "[16831 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(twitter[twitter.duplicated(subset=['id'])])\n",
    "print(users[users.duplicated(subset=['id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f068ba6-3733-437a-86a0-30b39d1c93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, username, name, location]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# removing duplicates (users where extracted multiple times because of 500 tweets per request limit)\n",
    "users.drop_duplicates(subset=['id'], inplace=True)\n",
    "print(users[users.duplicated(subset=['id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b7905d-3149-43bc-b68e-62f5970d6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tables\n",
    "df = pd.merge(twitter, users, how='left', left_on='author_id', right_on='id')\n",
    "df = df.rename(columns={\"id_x\": \"tweet_id\"}).drop(columns=['id_y'])\n",
    "# drop column id from users side, as it is the same as author_id from twitter table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8805c058-6779-4033-863e-ec44d4d0b657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          object\n",
       "author_id      int64\n",
       "tweet_id       int64\n",
       "created_at    object\n",
       "username      object\n",
       "name          object\n",
       "location      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da0b005-fb8d-4f3d-ad68-3ce2542ba71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change created_at dtype\n",
    "df['created_at'] = pd.to_datetime(df['created_at']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abb5e7ba-b6a6-42bb-8dcc-05347c1c2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ｗｈｅｎ ｉ ｆｅｅｌ ｅａｒｔｈｑｕａｋｅ， ｍｙ ｈａｎｄ ａｕｔｏｍａｔｉｃａｌｌｙ ...</td>\n",
       "      <td>2760893045</td>\n",
       "      <td>884990764933148673</td>\n",
       "      <td>2017-07-12 04:20:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ｗｈｅｎ ｉ ｆｅｅｌ ｅａｒｔｈｑｕａｋｅ， ｍｙ ｈａｎｄ ａｕｔｏｍａｔｉｃａｌｌｙ ...</td>\n",
       "      <td>3214732451</td>\n",
       "      <td>921250488313622528</td>\n",
       "      <td>2017-10-20 05:43:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ｗｈｅｎ　ｉ　ｆｅｅｌ　ｅａｒｔｈｑｕａｋｅ，　ｍｙ　ｈａｎｄ　ａｕｔｏｍａｔｉｃａｌｌｙ　...</td>\n",
       "      <td>36488329</td>\n",
       "      <td>928040346604523520</td>\n",
       "      <td>2017-11-07 23:23:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ｗｈｅｎ　ｉ　ｆｅｅｌ　ｅａｒｔｈｑｕａｋｅ，　ｍｙ　ｈａｎｄ　ａｕｔｏｍａｔｉｃａｌｌｙ　...</td>\n",
       "      <td>308947696</td>\n",
       "      <td>928030577537589248</td>\n",
       "      <td>2017-11-07 22:45:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ｗｈｅｎ　ｉ　ｆｅｅｌ　ｅａｒｔｈｑｕａｋｅ，　ｍｙ　ｈａｎｄ　ａｕｔｏｍａｔｉｃａｌｌｙ　...</td>\n",
       "      <td>3062164543</td>\n",
       "      <td>938577830752935936</td>\n",
       "      <td>2017-12-07 01:16:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517310</th>\n",
       "      <td>鹿児島で震度5強。：https://t.co/EKgCD3bD0Q鹿児島で震度5強。またです...</td>\n",
       "      <td>266278707</td>\n",
       "      <td>885140873863872512</td>\n",
       "      <td>2017-07-12 14:16:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517311</th>\n",
       "      <td>鹿児島　震度5強\\n\\nhttps://t.co/vm5PTMfJuh https://t....</td>\n",
       "      <td>875992792773738496</td>\n",
       "      <td>884609069700403200</td>\n",
       "      <td>2017-07-11 03:03:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517313</th>\n",
       "      <td>鹿児島で震度5強\\n\\n九州は散々やで…(*_*)\\n\\n地震情報 - Yahoo!天気・災...</td>\n",
       "      <td>86334263</td>\n",
       "      <td>884609347925426177</td>\n",
       "      <td>2017-07-11 03:04:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517315</th>\n",
       "      <td>鹿児島で震度5強の地震\\nhttps://t.co/Gl9wT2IQz4</td>\n",
       "      <td>2414138750</td>\n",
       "      <td>884609357027041281</td>\n",
       "      <td>2017-07-11 03:04:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517317</th>\n",
       "      <td>鹿児島で震度5強。\\n津波の心配なし。\\nhttps://t.co/kVOocEtyma</td>\n",
       "      <td>150649490</td>\n",
       "      <td>884608421156147201</td>\n",
       "      <td>2017-07-11 03:00:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309020 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  \\\n",
       "4         ｗｈｅｎ ｉ ｆｅｅｌ ｅａｒｔｈｑｕａｋｅ， ｍｙ ｈａｎｄ ａｕｔｏｍａｔｉｃａｌｌｙ ...   \n",
       "5         ｗｈｅｎ ｉ ｆｅｅｌ ｅａｒｔｈｑｕａｋｅ， ｍｙ ｈａｎｄ ａｕｔｏｍａｔｉｃａｌｌｙ ...   \n",
       "23        ｗｈｅｎ　ｉ　ｆｅｅｌ　ｅａｒｔｈｑｕａｋｅ，　ｍｙ　ｈａｎｄ　ａｕｔｏｍａｔｉｃａｌｌｙ　...   \n",
       "30        ｗｈｅｎ　ｉ　ｆｅｅｌ　ｅａｒｔｈｑｕａｋｅ，　ｍｙ　ｈａｎｄ　ａｕｔｏｍａｔｉｃａｌｌｙ　...   \n",
       "49        ｗｈｅｎ　ｉ　ｆｅｅｌ　ｅａｒｔｈｑｕａｋｅ，　ｍｙ　ｈａｎｄ　ａｕｔｏｍａｔｉｃａｌｌｙ　...   \n",
       "...                                                     ...   \n",
       "13517310  鹿児島で震度5強。：https://t.co/EKgCD3bD0Q鹿児島で震度5強。またです...   \n",
       "13517311  鹿児島　震度5強\\n\\nhttps://t.co/vm5PTMfJuh https://t....   \n",
       "13517313  鹿児島で震度5強\\n\\n九州は散々やで…(*_*)\\n\\n地震情報 - Yahoo!天気・災...   \n",
       "13517315               鹿児島で震度5強の地震\\nhttps://t.co/Gl9wT2IQz4   \n",
       "13517317       鹿児島で震度5強。\\n津波の心配なし。\\nhttps://t.co/kVOocEtyma   \n",
       "\n",
       "                   author_id            tweet_id          created_at username  \\\n",
       "4                 2760893045  884990764933148673 2017-07-12 04:20:15      NaN   \n",
       "5                 3214732451  921250488313622528 2017-10-20 05:43:27      NaN   \n",
       "23                  36488329  928040346604523520 2017-11-07 23:23:55      NaN   \n",
       "30                 308947696  928030577537589248 2017-11-07 22:45:06      NaN   \n",
       "49                3062164543  938577830752935936 2017-12-07 01:16:07      NaN   \n",
       "...                      ...                 ...                 ...      ...   \n",
       "13517310           266278707  885140873863872512 2017-07-12 14:16:44      NaN   \n",
       "13517311  875992792773738496  884609069700403200 2017-07-11 03:03:32      NaN   \n",
       "13517313            86334263  884609347925426177 2017-07-11 03:04:38      NaN   \n",
       "13517315          2414138750  884609357027041281 2017-07-11 03:04:40      NaN   \n",
       "13517317           150649490  884608421156147201 2017-07-11 03:00:57      NaN   \n",
       "\n",
       "         name  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "23        NaN  \n",
       "30        NaN  \n",
       "49        NaN  \n",
       "...       ...  \n",
       "13517310  NaN  \n",
       "13517311  NaN  \n",
       "13517313  NaN  \n",
       "13517315  NaN  \n",
       "13517317  NaN  \n",
       "\n",
       "[309020 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some users could not be inserted into postgreSQL table due to invalid characters. We identify them:\n",
    "df[df['username'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbfd49b-55b4-4086-9a44-9ba7173f2bed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2017, 7, 1) datetime.date(2017, 7, 2)\n",
      " datetime.date(2017, 7, 3) datetime.date(2017, 7, 4)\n",
      " datetime.date(2017, 7, 5) datetime.date(2017, 7, 6)\n",
      " datetime.date(2017, 7, 7) datetime.date(2017, 7, 8)\n",
      " datetime.date(2017, 7, 9) datetime.date(2017, 7, 10)\n",
      " datetime.date(2017, 7, 11) datetime.date(2017, 7, 12)\n",
      " datetime.date(2017, 7, 13) datetime.date(2017, 7, 14)\n",
      " datetime.date(2017, 7, 15) datetime.date(2017, 7, 16)\n",
      " datetime.date(2017, 7, 17) datetime.date(2017, 7, 18)\n",
      " datetime.date(2017, 7, 19) datetime.date(2017, 7, 20)\n",
      " datetime.date(2017, 7, 21) datetime.date(2017, 7, 22)\n",
      " datetime.date(2017, 7, 23) datetime.date(2017, 7, 24)\n",
      " datetime.date(2017, 7, 25) datetime.date(2017, 7, 26)\n",
      " datetime.date(2017, 7, 27) datetime.date(2017, 7, 28)\n",
      " datetime.date(2017, 7, 29) datetime.date(2017, 7, 30)\n",
      " datetime.date(2017, 7, 31) datetime.date(2017, 8, 1)\n",
      " datetime.date(2017, 8, 2) datetime.date(2017, 8, 3)\n",
      " datetime.date(2017, 8, 4) datetime.date(2017, 8, 5)\n",
      " datetime.date(2017, 8, 6) datetime.date(2017, 8, 7)\n",
      " datetime.date(2017, 8, 8) datetime.date(2017, 8, 9)\n",
      " datetime.date(2017, 8, 10) datetime.date(2017, 8, 11)\n",
      " datetime.date(2017, 8, 12) datetime.date(2017, 8, 13)\n",
      " datetime.date(2017, 8, 14) datetime.date(2017, 8, 15)\n",
      " datetime.date(2017, 8, 16) datetime.date(2017, 8, 17)\n",
      " datetime.date(2017, 8, 18) datetime.date(2017, 8, 19)\n",
      " datetime.date(2017, 8, 20) datetime.date(2017, 8, 21)\n",
      " datetime.date(2017, 8, 22) datetime.date(2017, 8, 23)\n",
      " datetime.date(2017, 8, 24) datetime.date(2017, 8, 25)\n",
      " datetime.date(2017, 8, 26) datetime.date(2017, 8, 27)\n",
      " datetime.date(2017, 8, 28) datetime.date(2017, 8, 29)\n",
      " datetime.date(2017, 8, 30) datetime.date(2017, 8, 31)\n",
      " datetime.date(2017, 9, 1) datetime.date(2017, 9, 2)\n",
      " datetime.date(2017, 9, 3) datetime.date(2017, 9, 4)\n",
      " datetime.date(2017, 9, 5) datetime.date(2017, 9, 6)\n",
      " datetime.date(2017, 9, 7) datetime.date(2017, 9, 8)\n",
      " datetime.date(2017, 9, 9) datetime.date(2017, 9, 10)\n",
      " datetime.date(2017, 9, 11) datetime.date(2017, 9, 12)\n",
      " datetime.date(2017, 9, 13) datetime.date(2017, 9, 14)\n",
      " datetime.date(2017, 9, 15) datetime.date(2017, 9, 16)\n",
      " datetime.date(2017, 9, 17) datetime.date(2017, 9, 18)\n",
      " datetime.date(2017, 9, 19) datetime.date(2017, 9, 20)\n",
      " datetime.date(2017, 9, 21) datetime.date(2017, 9, 22)\n",
      " datetime.date(2017, 9, 23) datetime.date(2017, 9, 24)\n",
      " datetime.date(2017, 9, 25) datetime.date(2017, 9, 26)\n",
      " datetime.date(2017, 9, 27) datetime.date(2017, 9, 28)\n",
      " datetime.date(2017, 9, 29) datetime.date(2017, 9, 30)\n",
      " datetime.date(2017, 10, 1) datetime.date(2017, 10, 2)\n",
      " datetime.date(2017, 10, 3) datetime.date(2017, 10, 4)\n",
      " datetime.date(2017, 10, 5) datetime.date(2017, 10, 6)\n",
      " datetime.date(2017, 10, 7) datetime.date(2017, 10, 8)\n",
      " datetime.date(2017, 10, 9) datetime.date(2017, 10, 10)\n",
      " datetime.date(2017, 10, 11) datetime.date(2017, 10, 12)\n",
      " datetime.date(2017, 10, 13) datetime.date(2017, 10, 14)\n",
      " datetime.date(2017, 10, 15) datetime.date(2017, 10, 16)\n",
      " datetime.date(2017, 10, 17) datetime.date(2017, 10, 18)\n",
      " datetime.date(2017, 10, 19) datetime.date(2017, 10, 20)\n",
      " datetime.date(2017, 10, 21) datetime.date(2017, 10, 22)\n",
      " datetime.date(2017, 10, 23) datetime.date(2017, 10, 24)\n",
      " datetime.date(2017, 10, 25) datetime.date(2017, 10, 26)\n",
      " datetime.date(2017, 10, 27) datetime.date(2017, 10, 28)\n",
      " datetime.date(2017, 10, 29) datetime.date(2017, 10, 30)\n",
      " datetime.date(2017, 10, 31) datetime.date(2017, 11, 1)\n",
      " datetime.date(2017, 11, 2) datetime.date(2017, 11, 3)\n",
      " datetime.date(2017, 11, 4) datetime.date(2017, 11, 5)\n",
      " datetime.date(2017, 11, 6) datetime.date(2017, 11, 7)\n",
      " datetime.date(2017, 11, 8) datetime.date(2017, 11, 9)\n",
      " datetime.date(2017, 11, 10) datetime.date(2017, 11, 11)\n",
      " datetime.date(2017, 11, 12) datetime.date(2017, 11, 13)\n",
      " datetime.date(2017, 11, 14) datetime.date(2017, 11, 15)\n",
      " datetime.date(2017, 11, 16) datetime.date(2017, 11, 17)\n",
      " datetime.date(2017, 11, 18) datetime.date(2017, 11, 19)\n",
      " datetime.date(2017, 11, 20) datetime.date(2017, 11, 21)\n",
      " datetime.date(2017, 11, 22) datetime.date(2017, 11, 23)\n",
      " datetime.date(2017, 11, 24) datetime.date(2017, 11, 25)\n",
      " datetime.date(2017, 11, 26) datetime.date(2017, 11, 27)\n",
      " datetime.date(2017, 11, 28) datetime.date(2017, 11, 29)\n",
      " datetime.date(2017, 11, 30) datetime.date(2017, 12, 1)\n",
      " datetime.date(2017, 12, 2) datetime.date(2017, 12, 3)\n",
      " datetime.date(2017, 12, 4) datetime.date(2017, 12, 5)\n",
      " datetime.date(2017, 12, 6) datetime.date(2017, 12, 7)\n",
      " datetime.date(2017, 12, 8) datetime.date(2017, 12, 9)\n",
      " datetime.date(2017, 12, 10) datetime.date(2017, 12, 11)\n",
      " datetime.date(2017, 12, 12) datetime.date(2017, 12, 13)\n",
      " datetime.date(2017, 12, 14) datetime.date(2017, 12, 15)\n",
      " datetime.date(2017, 12, 16) datetime.date(2017, 12, 17)\n",
      " datetime.date(2017, 12, 18) datetime.date(2017, 12, 19)\n",
      " datetime.date(2017, 12, 20) datetime.date(2017, 12, 21)\n",
      " datetime.date(2017, 12, 22) datetime.date(2017, 12, 23)\n",
      " datetime.date(2017, 12, 24) datetime.date(2017, 12, 25)\n",
      " datetime.date(2017, 12, 26) datetime.date(2017, 12, 27)\n",
      " datetime.date(2017, 12, 28) datetime.date(2017, 12, 29)\n",
      " datetime.date(2017, 12, 30) datetime.date(2017, 12, 31)\n",
      " datetime.date(2018, 10, 1) datetime.date(2018, 10, 2)\n",
      " datetime.date(2018, 10, 3) datetime.date(2018, 10, 4)\n",
      " datetime.date(2018, 10, 5) datetime.date(2018, 10, 6)\n",
      " datetime.date(2018, 10, 7) datetime.date(2018, 10, 8)\n",
      " datetime.date(2018, 10, 9) datetime.date(2018, 10, 10)\n",
      " datetime.date(2018, 10, 11) datetime.date(2018, 10, 12)\n",
      " datetime.date(2018, 10, 13) datetime.date(2018, 10, 14)\n",
      " datetime.date(2018, 10, 15) datetime.date(2018, 10, 16)\n",
      " datetime.date(2018, 10, 17) datetime.date(2018, 10, 18)\n",
      " datetime.date(2018, 10, 19) datetime.date(2018, 10, 20)\n",
      " datetime.date(2018, 10, 21) datetime.date(2018, 10, 22)\n",
      " datetime.date(2018, 10, 23) datetime.date(2018, 10, 24)\n",
      " datetime.date(2018, 10, 25) datetime.date(2018, 10, 26)\n",
      " datetime.date(2018, 10, 27) datetime.date(2018, 10, 28)\n",
      " datetime.date(2018, 10, 29) datetime.date(2018, 10, 30)\n",
      " datetime.date(2018, 10, 31) datetime.date(2018, 11, 1)\n",
      " datetime.date(2018, 11, 2) datetime.date(2018, 11, 3)\n",
      " datetime.date(2018, 11, 4) datetime.date(2018, 11, 5)\n",
      " datetime.date(2018, 11, 6) datetime.date(2018, 11, 7)\n",
      " datetime.date(2018, 11, 8) datetime.date(2018, 11, 9)\n",
      " datetime.date(2018, 11, 10) datetime.date(2018, 11, 11)\n",
      " datetime.date(2018, 11, 12) datetime.date(2018, 11, 13)\n",
      " datetime.date(2021, 7, 9)]\n"
     ]
    }
   ],
   "source": [
    "# we could either delete those tweets or try to insert those users. Since we have access to the data, we will insert it. However, getting the users by author_id would take too long, as there are \n",
    "# 240239 unique users missing. We will rather get the tweets with the users again for that timeframe, remove the invalid character and insert it into the table.\n",
    "missing = df[df.isna().any(axis=1)].copy()\n",
    "missing['created_at'] = pd.to_datetime(missing['created_at']).dt.date\n",
    "missing.sort_values(by='created_at', inplace=True)\n",
    "\n",
    "uniqueDates = missing['created_at'].unique()\n",
    "print(uniqueDates)\n",
    "# from the output we see the affected time periods are: 1.7.17-31.12.17, 1.7.18-13.10.18 and then one day on 9.7.21 (these we will delete, they are only a few tweets and won't change the analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb4e8f-47ea-4455-990b-c862263024b7",
   "metadata": {},
   "source": [
    "### Extract additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ab9b2de-4a80-40d0-8915-3ccc51f05d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = config['BEARER_TOKEN']\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAJY%2BNgEAAAAA5SvyA6cq3jifLadZEWMEiYgUj%2FI%3Dci6sbF0x3Ya5EckuWJ6L7M4RJhptE16APFL9PMnhZPZXulQg0I\"\n",
    "FILTER_QUERY = \"-from:quakeupdates -from:jojo2727 -from:MonitorSismico -from:MyComicalLife -from:news_sokuho_bot -from:DiariosRobot -from:EN_NERV -from:GDACS -from:earthquake_jp -from:EQAlerts -from:j1_quake -from:iSachinSrivstva -from:VolcanoEWS -from:ChileAlertaApp -from:earthb0t -from:sexy_vegetables -from:zishin3255 -from:everyEarthquake -from:MapQuake -from:swap_bot_bash -from:eq_map -from:eq_map_es -from:eq_map_ww -from:SEISMOinfo -from:VegaBajaWx -from:WatchOurCity -from:Keith_Event -from:SismoDetector -from:cvb_223 -from:ExBulletinUk -from:EMSC -from:StoixeioJewelry -from:megamodo -from:earthquakevt -from:QuakeBotter -from:twtaka_jp -from:EarthquakeTw -from:ENSO1998 -from:eq_map_ww2 -from:eq_map_es2\"\n",
    "\n",
    "\n",
    "start_time = '2018-07-01T00:00:00.000Z'\n",
    "end_time = \"2018-10-13T23:59:59.000Z\"\n",
    "query = \"earthquake -minor, -is:reply -is:retweet {0}\".format(FILTER_QUERY)\n",
    "max_results = \"500\"\n",
    "tweet_fields = \"created_at,author_id\"\n",
    "user_fields = 'username,location'\n",
    "expansions = 'author_id'\n",
    "counter = 0\n",
    "query_params = {'query': query, 'tweet.fields': tweet_fields, 'user.fields': user_fields, \\\n",
    "                'start_time': start_time, 'end_time': end_time, 'max_results': max_results, \\\n",
    "                'expansions': expansions}\n",
    "url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "headers = {\"Authorization\": \"Bearer \" + BEARER_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ea515e-c5c6-47f8-9012-f231bed0666c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst_tweets = []\n",
    "lst_users = []\n",
    "while True:\n",
    "    # get results according to url and query\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=query_params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "\n",
    "    # combine data to one\n",
    "    json_response = response.json()\n",
    "    if 'data' in json_response:\n",
    "        lst_tweets2 = lst_tweets2 + json_response['data']\n",
    "        lst_users2 = lst_users2 + json_response['includes']['users']\n",
    "\n",
    "    # check if more data available, if yes continue process\n",
    "    if 'meta' in json_response:\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            query_params['next_token'] = json_response['meta']['next_token']\n",
    "            next_token = json_response['meta']['next_token']\n",
    "          #  logging.info(\"Fetching next few tweets, next_token: \", query_params['next_token'])\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            if 'next_token' in query_params:\n",
    "                del query_params['next_token']\n",
    "            break\n",
    "    else:\n",
    "        if 'next_token' in query_params:\n",
    "            del query_params['next_token']\n",
    "            print('no meta in json_response')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6200ba9c-2eb7-4528-82b2-0d37d13ed0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "335c9548-e2ad-476c-8a3e-008707c3f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['location'], inplace=True)\n",
    "df.drop(columns=['location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c6d9b-f68a-4a06-b474-40dac5d511dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of memory issues the data was saved to csv and will be read in here again\n",
    "twe = pd.read_csv(\"matchingtweets.csv\")\n",
    "use = pd.read_csv(\"missingusers.csv\")\n",
    "\n",
    "df2 = pd.merge(twe, use, how='left', left_on='author_id', right_on='id')\n",
    "df2 = df2.rename(columns={\"id_x\": \"tweet_id\"}).drop(columns=['id_y'])\n",
    "\n",
    "# delete location because of no relevant information\n",
    "df2.drop(columns=['location'], inplace=True)\n",
    "df.drop(columns=['location'], inplace=True)\n",
    "\n",
    "df2['created_at'] = pd.to_datetime(df2['created_at']).dt.tz_localize(None)\n",
    "\n",
    "df3 = df2.append(df)\n",
    "df3.drop_duplicates(subset=['tweet_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0c5df-b457-4015-bd8e-d6a22a54b5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>776569</th>\n",
       "      <td>911360842528100352</td>\n",
       "      <td>2017-09-22 22:45:31</td>\n",
       "      <td>The reason Frida, the trapped little girl, gri...</td>\n",
       "      <td>186552155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26472</th>\n",
       "      <td>1059683238170542080</td>\n",
       "      <td>2018-11-06 05:45:46</td>\n",
       "      <td>02/14/14: I’m watching House of Cards (S2) in ...</td>\n",
       "      <td>156334774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54200</th>\n",
       "      <td>1056912735244562434</td>\n",
       "      <td>2018-10-29 14:16:47</td>\n",
       "      <td>0.4, 0.8, 1.1 \\nIf this appears on #OnlyConnec...</td>\n",
       "      <td>310455504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64102</th>\n",
       "      <td>1054783429970137088</td>\n",
       "      <td>2018-10-23 17:15:41</td>\n",
       "      <td>0.4 level earthquake today @NoFrackLancs  Time...</td>\n",
       "      <td>4331730273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106104</th>\n",
       "      <td>1052907078615031808</td>\n",
       "      <td>2018-10-18 12:59:44</td>\n",
       "      <td>074 // earthquake // #100daysofascent #100dayc...</td>\n",
       "      <td>23904102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514569</th>\n",
       "      <td>1052127631221514241</td>\n",
       "      <td>2018-10-16 09:22:29</td>\n",
       "      <td>「ドーン！」と音がしただけで何かよくわからなかったけど、最近多いらしい…\\n大地震の前兆とか...</td>\n",
       "      <td>550738293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514660</th>\n",
       "      <td>1061534708427706369</td>\n",
       "      <td>2018-11-11 08:22:51</td>\n",
       "      <td>この頃、また地震が多い…。\\n地震情報 - Yahoo!天気・災害 https://t.co...</td>\n",
       "      <td>110049763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515815</th>\n",
       "      <td>1058274420068741120</td>\n",
       "      <td>2018-11-02 08:27:38</td>\n",
       "      <td>カラスが騒がしかったのと、家鳴りがあったのはこれかな？\\n地震情報 - Yahoo!天気・災...</td>\n",
       "      <td>2966046025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13516249</th>\n",
       "      <td>1058266760590254080</td>\n",
       "      <td>2018-11-02 07:57:12</td>\n",
       "      <td>高知市内揺れたね、和歌山の方が震源みたい。#地震 #和歌山 #震度4 https://t.c...</td>\n",
       "      <td>198874833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517159</th>\n",
       "      <td>884608773515395074</td>\n",
       "      <td>2017-07-11 03:02:21</td>\n",
       "      <td>鹿児島湾で地震発生（2017年7月11日 11時56分）最大震度5強 https://t.c...</td>\n",
       "      <td>237587677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18653 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tweet_id          created_at  \\\n",
       "776569     911360842528100352 2017-09-22 22:45:31   \n",
       "26472     1059683238170542080 2018-11-06 05:45:46   \n",
       "54200     1056912735244562434 2018-10-29 14:16:47   \n",
       "64102     1054783429970137088 2018-10-23 17:15:41   \n",
       "106104    1052907078615031808 2018-10-18 12:59:44   \n",
       "...                       ...                 ...   \n",
       "13514569  1052127631221514241 2018-10-16 09:22:29   \n",
       "13514660  1061534708427706369 2018-11-11 08:22:51   \n",
       "13515815  1058274420068741120 2018-11-02 08:27:38   \n",
       "13516249  1058266760590254080 2018-11-02 07:57:12   \n",
       "13517159   884608773515395074 2017-07-11 03:02:21   \n",
       "\n",
       "                                                       text   author_id  \\\n",
       "776569    The reason Frida, the trapped little girl, gri...   186552155   \n",
       "26472     02/14/14: I’m watching House of Cards (S2) in ...   156334774   \n",
       "54200     0.4, 0.8, 1.1 \\nIf this appears on #OnlyConnec...   310455504   \n",
       "64102     0.4 level earthquake today @NoFrackLancs  Time...  4331730273   \n",
       "106104    074 // earthquake // #100daysofascent #100dayc...    23904102   \n",
       "...                                                     ...         ...   \n",
       "13514569  「ドーン！」と音がしただけで何かよくわからなかったけど、最近多いらしい…\\n大地震の前兆とか...   550738293   \n",
       "13514660  この頃、また地震が多い…。\\n地震情報 - Yahoo!天気・災害 https://t.co...   110049763   \n",
       "13515815  カラスが騒がしかったのと、家鳴りがあったのはこれかな？\\n地震情報 - Yahoo!天気・災...  2966046025   \n",
       "13516249  高知市内揺れたね、和歌山の方が震源みたい。#地震 #和歌山 #震度4 https://t.c...   198874833   \n",
       "13517159  鹿児島湾で地震発生（2017年7月11日 11時56分）最大震度5強 https://t.c...   237587677   \n",
       "\n",
       "         username  name  \n",
       "776569        NaN  jeff  \n",
       "26472         NaN   NaN  \n",
       "54200         NaN   NaN  \n",
       "64102         NaN   NaN  \n",
       "106104        NaN   NaN  \n",
       "...           ...   ...  \n",
       "13514569      NaN   NaN  \n",
       "13514660      NaN   NaN  \n",
       "13515815      NaN   NaN  \n",
       "13516249      NaN   NaN  \n",
       "13517159      NaN   NaN  \n",
       "\n",
       "[18653 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan again, on column username\n",
    "df3[df3['username'].isna()] # significantly less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26caf8d1-22be-492f-849c-b00882d54dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('temp_df3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12c408-19bd-4c66-bfd9-f7cd198631ea",
   "metadata": {},
   "source": [
    "## Remove Bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e93c92-18d0-45fb-b798-c47b1fc7d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"temp_df3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9588fb8-4162-4d0f-8b7c-d32c598c9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947618226762067969</td>\n",
       "      <td>2017-12-31 23:59:25</td>\n",
       "      <td>Mag: 4.9 - Depth: 241 km - UTC 11:48 PM - Mari...</td>\n",
       "      <td>912447782</td>\n",
       "      <td>Quake_Tracker</td>\n",
       "      <td>Earthquake Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947618166472970241</td>\n",
       "      <td>2017-12-31 23:59:11</td>\n",
       "      <td>Para #Jalisco Padres y Madres, Tenemos una sor...</td>\n",
       "      <td>69124342</td>\n",
       "      <td>QuakeAlarmMex</td>\n",
       "      <td>Quake Alarm México®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>947618145744732161</td>\n",
       "      <td>2017-12-31 23:59:06</td>\n",
       "      <td>My Little Hulk 🌈💪🏿💋 @sharred83 EARTHQUAKE lol ...</td>\n",
       "      <td>101987558</td>\n",
       "      <td>yeyodapoet</td>\n",
       "      <td>Melanie YeYo Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947618134327832576</td>\n",
       "      <td>2017-12-31 23:59:03</td>\n",
       "      <td>earthquake - M 4.9, Mariana Islands: 2017-12-3...</td>\n",
       "      <td>22224434</td>\n",
       "      <td>Recent_Quakes</td>\n",
       "      <td>Recent Earthquakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>947618008268201984</td>\n",
       "      <td>2017-12-31 23:58:33</td>\n",
       "      <td>4.9 earthquake occurred near Pagan Reg., N. Ma...</td>\n",
       "      <td>3137517334</td>\n",
       "      <td>myearthquakeapp</td>\n",
       "      <td>My Earthquake Alerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020869</th>\n",
       "      <td>1209736774441787392</td>\n",
       "      <td>2019-12-25 07:24:57</td>\n",
       "      <td>龍が空に昇っていくような雲。これは太い地震雲かな。#地震雲 #Earthquake http...</td>\n",
       "      <td>1131942533997555714</td>\n",
       "      <td>ranze_makabec</td>\n",
       "      <td>étranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020870</th>\n",
       "      <td>1333294538593505280</td>\n",
       "      <td>2020-11-30 06:19:24</td>\n",
       "      <td>龍のような、長い雲が出ていた。\\n西の方から東へかけて\\n\\n2020/11/30\\n15時...</td>\n",
       "      <td>1110157662610550784</td>\n",
       "      <td>irisbluex</td>\n",
       "      <td>IRIS BLUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020871</th>\n",
       "      <td>1358646689133826048</td>\n",
       "      <td>2021-02-08 05:19:47</td>\n",
       "      <td>龍騰斷橋(北斷橋) ，921地震遺址。\\nThe Longteng bridge. The ...</td>\n",
       "      <td>1311171231983394816</td>\n",
       "      <td>Evy_Myers</td>\n",
       "      <td>Evy Myers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020872</th>\n",
       "      <td>1358647261010350080</td>\n",
       "      <td>2021-02-08 05:22:04</td>\n",
       "      <td>龍騰斷橋(南斷橋) ，921地震遺址。\\nThe Longteng bridge. The ...</td>\n",
       "      <td>1311171231983394816</td>\n",
       "      <td>Evy_Myers</td>\n",
       "      <td>Evy Myers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020873</th>\n",
       "      <td>726953883726049280</td>\n",
       "      <td>2016-05-02 01:58:06</td>\n",
       "      <td>龍騰斷橋的時間在1935那年暫停了，但生命的延續確是生生不息自有出路。 #1935 #ear...</td>\n",
       "      <td>398111366</td>\n",
       "      <td>petechou11</td>\n",
       "      <td>Pete Chou</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14020874 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tweet_id           created_at  \\\n",
       "0          947618226762067969  2017-12-31 23:59:25   \n",
       "1          947618166472970241  2017-12-31 23:59:11   \n",
       "2          947618145744732161  2017-12-31 23:59:06   \n",
       "3          947618134327832576  2017-12-31 23:59:03   \n",
       "4          947618008268201984  2017-12-31 23:58:33   \n",
       "...                       ...                  ...   \n",
       "14020869  1209736774441787392  2019-12-25 07:24:57   \n",
       "14020870  1333294538593505280  2020-11-30 06:19:24   \n",
       "14020871  1358646689133826048  2021-02-08 05:19:47   \n",
       "14020872  1358647261010350080  2021-02-08 05:22:04   \n",
       "14020873   726953883726049280  2016-05-02 01:58:06   \n",
       "\n",
       "                                                       text  \\\n",
       "0         Mag: 4.9 - Depth: 241 km - UTC 11:48 PM - Mari...   \n",
       "1         Para #Jalisco Padres y Madres, Tenemos una sor...   \n",
       "2         My Little Hulk 🌈💪🏿💋 @sharred83 EARTHQUAKE lol ...   \n",
       "3         earthquake - M 4.9, Mariana Islands: 2017-12-3...   \n",
       "4         4.9 earthquake occurred near Pagan Reg., N. Ma...   \n",
       "...                                                     ...   \n",
       "14020869  龍が空に昇っていくような雲。これは太い地震雲かな。#地震雲 #Earthquake http...   \n",
       "14020870  龍のような、長い雲が出ていた。\\n西の方から東へかけて\\n\\n2020/11/30\\n15時...   \n",
       "14020871  龍騰斷橋(北斷橋) ，921地震遺址。\\nThe Longteng bridge. The ...   \n",
       "14020872  龍騰斷橋(南斷橋) ，921地震遺址。\\nThe Longteng bridge. The ...   \n",
       "14020873  龍騰斷橋的時間在1935那年暫停了，但生命的延續確是生生不息自有出路。 #1935 #ear...   \n",
       "\n",
       "                    author_id         username                  name  \n",
       "0                   912447782    Quake_Tracker     Earthquake Report  \n",
       "1                    69124342    QuakeAlarmMex   Quake Alarm México®  \n",
       "2                   101987558       yeyodapoet   Melanie YeYo Carter  \n",
       "3                    22224434    Recent_Quakes    Recent Earthquakes  \n",
       "4                  3137517334  myearthquakeapp  My Earthquake Alerts  \n",
       "...                       ...              ...                   ...  \n",
       "14020869  1131942533997555714    ranze_makabec              étranger  \n",
       "14020870  1110157662610550784        irisbluex             IRIS BLUE  \n",
       "14020871  1311171231983394816        Evy_Myers             Evy Myers  \n",
       "14020872  1311171231983394816        Evy_Myers             Evy Myers  \n",
       "14020873            398111366       petechou11             Pete Chou  \n",
       "\n",
       "[14020874 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f92614-ede1-4042-a143-790a27a773d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out accounts with more or equal to 175 postings\n",
    "df = df.loc[df['value'] > 10].sort_values(by=['value'])\n",
    "lst_bots = df_a.username.tolist()\n",
    "\n",
    "# add -from: operator to each entry in list \n",
    "append_str = '-from:'\n",
    "lst_filter = [append_str + sub for sub in lst_bots]\n",
    "\n",
    "# convert list to a string suitable for the query\n",
    "filter_names_query = ' '.join(lst_filter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
