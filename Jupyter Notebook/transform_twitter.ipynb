{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1270f0f8-9022-46ae-ae35-26624b2df0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226ad16-aabb-4b0e-9afc-95d7371cc426",
   "metadata": {},
   "source": [
    "### Connection to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a0cb0f-5ad5-4bcf-8acf-87ad5ab842e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the connection details for the rds db from .env file\n",
    "config = dotenv_values(\".env\")  \n",
    "HOST_RDS = config['HOST_RDS']\n",
    "DBNAME_RDS = config['DBNAME_RDS']\n",
    "USER_RDS = config['USER_RDS']\n",
    "PASSWORD_RDS = config['PASSWORD_RDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48be2f06-0c64-4a3f-a4df-8aa5e742a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from postgreSQL tables\n",
    "engine_str = 'postgresql+psycopg2://' + USER_RDS + ':' + PASSWORD_RDS + \"@\" + HOST_RDS + \":5432/dbeq\"\n",
    "engine = create_engine(engine_str)\n",
    "dbConnection = engine.connect()\n",
    "twitter = pd.read_sql(\"SELECT * FROM dl_twitter\", dbConnection)\n",
    "users = pd.read_sql(\"SELECT * from dl_twitterusers\", dbConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bb0dc88-0f84-4d37-8c47-e1da83d89ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, author_id, id, created_at]\n",
      "Index: []\n",
      "                          id         username                          name  \\\n",
      "11                       246           blaine               Blaine Cook ğŸ’‰ğŸ’‰ğŸ‰   \n",
      "823                   615403       avalonstar  Bryan Veloso ğŸŒŸ Forging Ahead   \n",
      "873                   630163          superic                 Eric Willis ğŸ¦ƒ   \n",
      "886                   634703            k3nnr                     k3nnr.ogg   \n",
      "889                   635463    FauziKHamadeh              Fauzi K. Hamadeh   \n",
      "...                      ...              ...                           ...   \n",
      "2501742  1406414300311212034   yourlight51129      ğŸŒŸğŸŒ™ ğŸ¥šlet's shine together   \n",
      "2501794  1406530652841852934        NewsBits_                     News Bits   \n",
      "2502333  1407964313793425411  viral48official                       viral48   \n",
      "2505737  1417005186262867973        MNSTAPLZA                   I MISS BTS.   \n",
      "2507964  1422990264147185666  NewsFromBehind1              News From Behind   \n",
      "\n",
      "                              location  \n",
      "11                          Nelson, BC  \n",
      "823           Silver Lake, Los Angeles  \n",
      "873                       Pacifica, CA  \n",
      "886                           Bay Area  \n",
      "889                      San Mateo, CA  \n",
      "...                                ...  \n",
      "2501742       Republik der Philippinen  \n",
      "2501794   Vereinigte Arabische Emirate  \n",
      "2502333               Bengaluru, India  \n",
      "2505737  him/her | 20 | bi | genderfld  \n",
      "2507964                  à¤•à¥‹à¤²à¤•à¤¾à¤¤à¤¾, à¤­à¤¾à¤°à¤¤  \n",
      "\n",
      "[16831 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(twitter[twitter.duplicated(subset=['id'])])\n",
    "print(users[users.duplicated(subset=['id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f068ba6-3733-437a-86a0-30b39d1c93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, username, name, location]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# removing duplicates (users where extracted multiple times because of 500 tweets per request limit)\n",
    "users.drop_duplicates(subset=['id'], inplace=True)\n",
    "print(users[users.duplicated(subset=['id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b7905d-3149-43bc-b68e-62f5970d6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tables\n",
    "df = pd.merge(twitter, users, how='left', left_on='author_id', right_on='id')\n",
    "df = df.rename(columns={\"id_x\": \"tweet_id\"}).drop(columns=['id_y'])\n",
    "# drop column id from users side, as it is the same as author_id from twitter table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8805c058-6779-4033-863e-ec44d4d0b657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          object\n",
       "author_id      int64\n",
       "tweet_id       int64\n",
       "created_at    object\n",
       "username      object\n",
       "name          object\n",
       "location      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da0b005-fb8d-4f3d-ad68-3ce2542ba71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change created_at dtype\n",
    "df['created_at'] = pd.to_datetime(df['created_at']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abb5e7ba-b6a6-42bb-8dcc-05347c1c2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ï½—ï½ˆï½…ï½ ï½‰ ï½†ï½…ï½…ï½Œ ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œ ï½ï½™ ï½ˆï½ï½ï½„ ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ ...</td>\n",
       "      <td>2760893045</td>\n",
       "      <td>884990764933148673</td>\n",
       "      <td>2017-07-12 04:20:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ï½—ï½ˆï½…ï½ ï½‰ ï½†ï½…ï½…ï½Œ ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œ ï½ï½™ ï½ˆï½ï½ï½„ ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ ...</td>\n",
       "      <td>3214732451</td>\n",
       "      <td>921250488313622528</td>\n",
       "      <td>2017-10-20 05:43:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ï½—ï½ˆï½…ï½ã€€ï½‰ã€€ï½†ï½…ï½…ï½Œã€€ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œã€€ï½ï½™ã€€ï½ˆï½ï½ï½„ã€€ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ã€€...</td>\n",
       "      <td>36488329</td>\n",
       "      <td>928040346604523520</td>\n",
       "      <td>2017-11-07 23:23:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ï½—ï½ˆï½…ï½ã€€ï½‰ã€€ï½†ï½…ï½…ï½Œã€€ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œã€€ï½ï½™ã€€ï½ˆï½ï½ï½„ã€€ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ã€€...</td>\n",
       "      <td>308947696</td>\n",
       "      <td>928030577537589248</td>\n",
       "      <td>2017-11-07 22:45:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ï½—ï½ˆï½…ï½ã€€ï½‰ã€€ï½†ï½…ï½…ï½Œã€€ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œã€€ï½ï½™ã€€ï½ˆï½ï½ï½„ã€€ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ã€€...</td>\n",
       "      <td>3062164543</td>\n",
       "      <td>938577830752935936</td>\n",
       "      <td>2017-12-07 01:16:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517310</th>\n",
       "      <td>é¹¿å…å³¶ã§éœ‡åº¦5å¼·ã€‚ï¼šhttps://t.co/EKgCD3bD0Qé¹¿å…å³¶ã§éœ‡åº¦5å¼·ã€‚ã¾ãŸã§ã™...</td>\n",
       "      <td>266278707</td>\n",
       "      <td>885140873863872512</td>\n",
       "      <td>2017-07-12 14:16:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517311</th>\n",
       "      <td>é¹¿å…å³¶ã€€éœ‡åº¦5å¼·\\n\\nhttps://t.co/vm5PTMfJuh https://t....</td>\n",
       "      <td>875992792773738496</td>\n",
       "      <td>884609069700403200</td>\n",
       "      <td>2017-07-11 03:03:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517313</th>\n",
       "      <td>é¹¿å…å³¶ã§éœ‡åº¦5å¼·\\n\\nä¹å·ã¯æ•£ã€…ã‚„ã§â€¦(*_*)\\n\\nåœ°éœ‡æƒ…å ± - Yahoo!å¤©æ°—ãƒ»ç½...</td>\n",
       "      <td>86334263</td>\n",
       "      <td>884609347925426177</td>\n",
       "      <td>2017-07-11 03:04:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517315</th>\n",
       "      <td>é¹¿å…å³¶ã§éœ‡åº¦5å¼·ã®åœ°éœ‡\\nhttps://t.co/Gl9wT2IQz4</td>\n",
       "      <td>2414138750</td>\n",
       "      <td>884609357027041281</td>\n",
       "      <td>2017-07-11 03:04:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517317</th>\n",
       "      <td>é¹¿å…å³¶ã§éœ‡åº¦5å¼·ã€‚\\næ´¥æ³¢ã®å¿ƒé…ãªã—ã€‚\\nhttps://t.co/kVOocEtyma</td>\n",
       "      <td>150649490</td>\n",
       "      <td>884608421156147201</td>\n",
       "      <td>2017-07-11 03:00:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309020 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  \\\n",
       "4         ï½—ï½ˆï½…ï½ ï½‰ ï½†ï½…ï½…ï½Œ ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œ ï½ï½™ ï½ˆï½ï½ï½„ ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ ...   \n",
       "5         ï½—ï½ˆï½…ï½ ï½‰ ï½†ï½…ï½…ï½Œ ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œ ï½ï½™ ï½ˆï½ï½ï½„ ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ ...   \n",
       "23        ï½—ï½ˆï½…ï½ã€€ï½‰ã€€ï½†ï½…ï½…ï½Œã€€ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œã€€ï½ï½™ã€€ï½ˆï½ï½ï½„ã€€ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ã€€...   \n",
       "30        ï½—ï½ˆï½…ï½ã€€ï½‰ã€€ï½†ï½…ï½…ï½Œã€€ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œã€€ï½ï½™ã€€ï½ˆï½ï½ï½„ã€€ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ã€€...   \n",
       "49        ï½—ï½ˆï½…ï½ã€€ï½‰ã€€ï½†ï½…ï½…ï½Œã€€ï½…ï½ï½’ï½”ï½ˆï½‘ï½•ï½ï½‹ï½…ï¼Œã€€ï½ï½™ã€€ï½ˆï½ï½ï½„ã€€ï½ï½•ï½”ï½ï½ï½ï½”ï½‰ï½ƒï½ï½Œï½Œï½™ã€€...   \n",
       "...                                                     ...   \n",
       "13517310  é¹¿å…å³¶ã§éœ‡åº¦5å¼·ã€‚ï¼šhttps://t.co/EKgCD3bD0Qé¹¿å…å³¶ã§éœ‡åº¦5å¼·ã€‚ã¾ãŸã§ã™...   \n",
       "13517311  é¹¿å…å³¶ã€€éœ‡åº¦5å¼·\\n\\nhttps://t.co/vm5PTMfJuh https://t....   \n",
       "13517313  é¹¿å…å³¶ã§éœ‡åº¦5å¼·\\n\\nä¹å·ã¯æ•£ã€…ã‚„ã§â€¦(*_*)\\n\\nåœ°éœ‡æƒ…å ± - Yahoo!å¤©æ°—ãƒ»ç½...   \n",
       "13517315               é¹¿å…å³¶ã§éœ‡åº¦5å¼·ã®åœ°éœ‡\\nhttps://t.co/Gl9wT2IQz4   \n",
       "13517317       é¹¿å…å³¶ã§éœ‡åº¦5å¼·ã€‚\\næ´¥æ³¢ã®å¿ƒé…ãªã—ã€‚\\nhttps://t.co/kVOocEtyma   \n",
       "\n",
       "                   author_id            tweet_id          created_at username  \\\n",
       "4                 2760893045  884990764933148673 2017-07-12 04:20:15      NaN   \n",
       "5                 3214732451  921250488313622528 2017-10-20 05:43:27      NaN   \n",
       "23                  36488329  928040346604523520 2017-11-07 23:23:55      NaN   \n",
       "30                 308947696  928030577537589248 2017-11-07 22:45:06      NaN   \n",
       "49                3062164543  938577830752935936 2017-12-07 01:16:07      NaN   \n",
       "...                      ...                 ...                 ...      ...   \n",
       "13517310           266278707  885140873863872512 2017-07-12 14:16:44      NaN   \n",
       "13517311  875992792773738496  884609069700403200 2017-07-11 03:03:32      NaN   \n",
       "13517313            86334263  884609347925426177 2017-07-11 03:04:38      NaN   \n",
       "13517315          2414138750  884609357027041281 2017-07-11 03:04:40      NaN   \n",
       "13517317           150649490  884608421156147201 2017-07-11 03:00:57      NaN   \n",
       "\n",
       "         name  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "23        NaN  \n",
       "30        NaN  \n",
       "49        NaN  \n",
       "...       ...  \n",
       "13517310  NaN  \n",
       "13517311  NaN  \n",
       "13517313  NaN  \n",
       "13517315  NaN  \n",
       "13517317  NaN  \n",
       "\n",
       "[309020 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some users could not be inserted into postgreSQL table due to invalid characters. We identify them:\n",
    "df[df['username'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbfd49b-55b4-4086-9a44-9ba7173f2bed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2017, 7, 1) datetime.date(2017, 7, 2)\n",
      " datetime.date(2017, 7, 3) datetime.date(2017, 7, 4)\n",
      " datetime.date(2017, 7, 5) datetime.date(2017, 7, 6)\n",
      " datetime.date(2017, 7, 7) datetime.date(2017, 7, 8)\n",
      " datetime.date(2017, 7, 9) datetime.date(2017, 7, 10)\n",
      " datetime.date(2017, 7, 11) datetime.date(2017, 7, 12)\n",
      " datetime.date(2017, 7, 13) datetime.date(2017, 7, 14)\n",
      " datetime.date(2017, 7, 15) datetime.date(2017, 7, 16)\n",
      " datetime.date(2017, 7, 17) datetime.date(2017, 7, 18)\n",
      " datetime.date(2017, 7, 19) datetime.date(2017, 7, 20)\n",
      " datetime.date(2017, 7, 21) datetime.date(2017, 7, 22)\n",
      " datetime.date(2017, 7, 23) datetime.date(2017, 7, 24)\n",
      " datetime.date(2017, 7, 25) datetime.date(2017, 7, 26)\n",
      " datetime.date(2017, 7, 27) datetime.date(2017, 7, 28)\n",
      " datetime.date(2017, 7, 29) datetime.date(2017, 7, 30)\n",
      " datetime.date(2017, 7, 31) datetime.date(2017, 8, 1)\n",
      " datetime.date(2017, 8, 2) datetime.date(2017, 8, 3)\n",
      " datetime.date(2017, 8, 4) datetime.date(2017, 8, 5)\n",
      " datetime.date(2017, 8, 6) datetime.date(2017, 8, 7)\n",
      " datetime.date(2017, 8, 8) datetime.date(2017, 8, 9)\n",
      " datetime.date(2017, 8, 10) datetime.date(2017, 8, 11)\n",
      " datetime.date(2017, 8, 12) datetime.date(2017, 8, 13)\n",
      " datetime.date(2017, 8, 14) datetime.date(2017, 8, 15)\n",
      " datetime.date(2017, 8, 16) datetime.date(2017, 8, 17)\n",
      " datetime.date(2017, 8, 18) datetime.date(2017, 8, 19)\n",
      " datetime.date(2017, 8, 20) datetime.date(2017, 8, 21)\n",
      " datetime.date(2017, 8, 22) datetime.date(2017, 8, 23)\n",
      " datetime.date(2017, 8, 24) datetime.date(2017, 8, 25)\n",
      " datetime.date(2017, 8, 26) datetime.date(2017, 8, 27)\n",
      " datetime.date(2017, 8, 28) datetime.date(2017, 8, 29)\n",
      " datetime.date(2017, 8, 30) datetime.date(2017, 8, 31)\n",
      " datetime.date(2017, 9, 1) datetime.date(2017, 9, 2)\n",
      " datetime.date(2017, 9, 3) datetime.date(2017, 9, 4)\n",
      " datetime.date(2017, 9, 5) datetime.date(2017, 9, 6)\n",
      " datetime.date(2017, 9, 7) datetime.date(2017, 9, 8)\n",
      " datetime.date(2017, 9, 9) datetime.date(2017, 9, 10)\n",
      " datetime.date(2017, 9, 11) datetime.date(2017, 9, 12)\n",
      " datetime.date(2017, 9, 13) datetime.date(2017, 9, 14)\n",
      " datetime.date(2017, 9, 15) datetime.date(2017, 9, 16)\n",
      " datetime.date(2017, 9, 17) datetime.date(2017, 9, 18)\n",
      " datetime.date(2017, 9, 19) datetime.date(2017, 9, 20)\n",
      " datetime.date(2017, 9, 21) datetime.date(2017, 9, 22)\n",
      " datetime.date(2017, 9, 23) datetime.date(2017, 9, 24)\n",
      " datetime.date(2017, 9, 25) datetime.date(2017, 9, 26)\n",
      " datetime.date(2017, 9, 27) datetime.date(2017, 9, 28)\n",
      " datetime.date(2017, 9, 29) datetime.date(2017, 9, 30)\n",
      " datetime.date(2017, 10, 1) datetime.date(2017, 10, 2)\n",
      " datetime.date(2017, 10, 3) datetime.date(2017, 10, 4)\n",
      " datetime.date(2017, 10, 5) datetime.date(2017, 10, 6)\n",
      " datetime.date(2017, 10, 7) datetime.date(2017, 10, 8)\n",
      " datetime.date(2017, 10, 9) datetime.date(2017, 10, 10)\n",
      " datetime.date(2017, 10, 11) datetime.date(2017, 10, 12)\n",
      " datetime.date(2017, 10, 13) datetime.date(2017, 10, 14)\n",
      " datetime.date(2017, 10, 15) datetime.date(2017, 10, 16)\n",
      " datetime.date(2017, 10, 17) datetime.date(2017, 10, 18)\n",
      " datetime.date(2017, 10, 19) datetime.date(2017, 10, 20)\n",
      " datetime.date(2017, 10, 21) datetime.date(2017, 10, 22)\n",
      " datetime.date(2017, 10, 23) datetime.date(2017, 10, 24)\n",
      " datetime.date(2017, 10, 25) datetime.date(2017, 10, 26)\n",
      " datetime.date(2017, 10, 27) datetime.date(2017, 10, 28)\n",
      " datetime.date(2017, 10, 29) datetime.date(2017, 10, 30)\n",
      " datetime.date(2017, 10, 31) datetime.date(2017, 11, 1)\n",
      " datetime.date(2017, 11, 2) datetime.date(2017, 11, 3)\n",
      " datetime.date(2017, 11, 4) datetime.date(2017, 11, 5)\n",
      " datetime.date(2017, 11, 6) datetime.date(2017, 11, 7)\n",
      " datetime.date(2017, 11, 8) datetime.date(2017, 11, 9)\n",
      " datetime.date(2017, 11, 10) datetime.date(2017, 11, 11)\n",
      " datetime.date(2017, 11, 12) datetime.date(2017, 11, 13)\n",
      " datetime.date(2017, 11, 14) datetime.date(2017, 11, 15)\n",
      " datetime.date(2017, 11, 16) datetime.date(2017, 11, 17)\n",
      " datetime.date(2017, 11, 18) datetime.date(2017, 11, 19)\n",
      " datetime.date(2017, 11, 20) datetime.date(2017, 11, 21)\n",
      " datetime.date(2017, 11, 22) datetime.date(2017, 11, 23)\n",
      " datetime.date(2017, 11, 24) datetime.date(2017, 11, 25)\n",
      " datetime.date(2017, 11, 26) datetime.date(2017, 11, 27)\n",
      " datetime.date(2017, 11, 28) datetime.date(2017, 11, 29)\n",
      " datetime.date(2017, 11, 30) datetime.date(2017, 12, 1)\n",
      " datetime.date(2017, 12, 2) datetime.date(2017, 12, 3)\n",
      " datetime.date(2017, 12, 4) datetime.date(2017, 12, 5)\n",
      " datetime.date(2017, 12, 6) datetime.date(2017, 12, 7)\n",
      " datetime.date(2017, 12, 8) datetime.date(2017, 12, 9)\n",
      " datetime.date(2017, 12, 10) datetime.date(2017, 12, 11)\n",
      " datetime.date(2017, 12, 12) datetime.date(2017, 12, 13)\n",
      " datetime.date(2017, 12, 14) datetime.date(2017, 12, 15)\n",
      " datetime.date(2017, 12, 16) datetime.date(2017, 12, 17)\n",
      " datetime.date(2017, 12, 18) datetime.date(2017, 12, 19)\n",
      " datetime.date(2017, 12, 20) datetime.date(2017, 12, 21)\n",
      " datetime.date(2017, 12, 22) datetime.date(2017, 12, 23)\n",
      " datetime.date(2017, 12, 24) datetime.date(2017, 12, 25)\n",
      " datetime.date(2017, 12, 26) datetime.date(2017, 12, 27)\n",
      " datetime.date(2017, 12, 28) datetime.date(2017, 12, 29)\n",
      " datetime.date(2017, 12, 30) datetime.date(2017, 12, 31)\n",
      " datetime.date(2018, 10, 1) datetime.date(2018, 10, 2)\n",
      " datetime.date(2018, 10, 3) datetime.date(2018, 10, 4)\n",
      " datetime.date(2018, 10, 5) datetime.date(2018, 10, 6)\n",
      " datetime.date(2018, 10, 7) datetime.date(2018, 10, 8)\n",
      " datetime.date(2018, 10, 9) datetime.date(2018, 10, 10)\n",
      " datetime.date(2018, 10, 11) datetime.date(2018, 10, 12)\n",
      " datetime.date(2018, 10, 13) datetime.date(2018, 10, 14)\n",
      " datetime.date(2018, 10, 15) datetime.date(2018, 10, 16)\n",
      " datetime.date(2018, 10, 17) datetime.date(2018, 10, 18)\n",
      " datetime.date(2018, 10, 19) datetime.date(2018, 10, 20)\n",
      " datetime.date(2018, 10, 21) datetime.date(2018, 10, 22)\n",
      " datetime.date(2018, 10, 23) datetime.date(2018, 10, 24)\n",
      " datetime.date(2018, 10, 25) datetime.date(2018, 10, 26)\n",
      " datetime.date(2018, 10, 27) datetime.date(2018, 10, 28)\n",
      " datetime.date(2018, 10, 29) datetime.date(2018, 10, 30)\n",
      " datetime.date(2018, 10, 31) datetime.date(2018, 11, 1)\n",
      " datetime.date(2018, 11, 2) datetime.date(2018, 11, 3)\n",
      " datetime.date(2018, 11, 4) datetime.date(2018, 11, 5)\n",
      " datetime.date(2018, 11, 6) datetime.date(2018, 11, 7)\n",
      " datetime.date(2018, 11, 8) datetime.date(2018, 11, 9)\n",
      " datetime.date(2018, 11, 10) datetime.date(2018, 11, 11)\n",
      " datetime.date(2018, 11, 12) datetime.date(2018, 11, 13)\n",
      " datetime.date(2021, 7, 9)]\n"
     ]
    }
   ],
   "source": [
    "# we could either delete those tweets or try to insert those users. Since we have access to the data, we will insert it. However, getting the users by author_id would take too long, as there are \n",
    "# 240239 unique users missing. We will rather get the tweets with the users again for that timeframe, remove the invalid character and insert it into the table.\n",
    "missing = df[df.isna().any(axis=1)].copy()\n",
    "missing['created_at'] = pd.to_datetime(missing['created_at']).dt.date\n",
    "missing.sort_values(by='created_at', inplace=True)\n",
    "\n",
    "uniqueDates = missing['created_at'].unique()\n",
    "print(uniqueDates)\n",
    "# from the output we see the affected time periods are: 1.7.17-31.12.17, 1.7.18-13.10.18 and then one day on 9.7.21 (these we will delete, they are only a few tweets and won't change the analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb4e8f-47ea-4455-990b-c862263024b7",
   "metadata": {},
   "source": [
    "### Extract additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ab9b2de-4a80-40d0-8915-3ccc51f05d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = config['BEARER_TOKEN']\n",
    "FILTER_QUERY = \"-from:quakeupdates -from:jojo2727 -from:MonitorSismico -from:MyComicalLife -from:news_sokuho_bot -from:DiariosRobot -from:EN_NERV -from:GDACS -from:earthquake_jp -from:EQAlerts -from:j1_quake -from:iSachinSrivstva -from:VolcanoEWS -from:ChileAlertaApp -from:earthb0t -from:sexy_vegetables -from:zishin3255 -from:everyEarthquake -from:MapQuake -from:swap_bot_bash -from:eq_map -from:eq_map_es -from:eq_map_ww -from:SEISMOinfo -from:VegaBajaWx -from:WatchOurCity -from:Keith_Event -from:SismoDetector -from:cvb_223 -from:ExBulletinUk -from:EMSC -from:StoixeioJewelry -from:megamodo -from:earthquakevt -from:QuakeBotter -from:twtaka_jp -from:EarthquakeTw -from:ENSO1998 -from:eq_map_ww2 -from:eq_map_es2\"\n",
    "\n",
    "\n",
    "start_time = '2017-07-01T00:00:00.000Z'\n",
    "end_time = \"2017-12-31T23:59:59.000Z\"\n",
    "query = \"earthquake -minor, -is:reply -is:retweet {0}\".format(FILTER_QUERY)\n",
    "max_results = \"500\"\n",
    "tweet_fields = \"created_at,author_id\"\n",
    "user_fields = 'username,location'\n",
    "expansions = 'author_id'\n",
    "counter = 0\n",
    "query_params = {'query': query, 'tweet.fields': tweet_fields, 'user.fields': user_fields, \\\n",
    "                'start_time': start_time, 'end_time': end_time, 'max_results': max_results, \\\n",
    "                'expansions': expansions}\n",
    "url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "headers = {\"Authorization\": \"Bearer \" + BEARER_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ea515e-c5c6-47f8-9012-f231bed0666c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst_tweets = []\n",
    "lst_users = []\n",
    "while True:\n",
    "    # get results according to url and query\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=query_params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "\n",
    "    # combine data to one\n",
    "    json_response = response.json()\n",
    "    if 'data' in json_response:\n",
    "        lst_tweets = lst_tweets + json_response['data']\n",
    "        lst_users = lst_users + json_response['includes']['users']\n",
    "\n",
    "    # check if more data available, if yes continue process\n",
    "    if 'meta' in json_response:\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            query_params['next_token'] = json_response['meta']['next_token']\n",
    "            next_token = json_response['meta']['next_token']\n",
    "          #  logging.info(\"Fetching next few tweets, next_token: \", query_params['next_token'])\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            if 'next_token' in query_params:\n",
    "                del query_params['next_token']\n",
    "            break\n",
    "    else:\n",
    "        if 'next_token' in query_params:\n",
    "            del query_params['next_token']\n",
    "            print('no meta in json_response')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcce1d2-afc0-494a-a2a6-71c0bd07dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.DataFrame(lst_tweets)\n",
    "df_u = pd.DataFrame(lst_users)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c6d9b-f68a-4a06-b474-40dac5d511dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of memory issues the data was saved to csv and will be read in here again\n",
    "twe = pd.read_csv(\"matchingtweets.csv\")\n",
    "use = pd.read_csv(\"missingusers.csv\")\n",
    "\n",
    "df2 = pd.merge(twe, use, how='left', left_on='author_id', right_on='id')\n",
    "df2 = df2.rename(columns={\"id_x\": \"tweet_id\"}).drop(columns=['id_y'])\n",
    "\n",
    "# delete location because of no relevant information\n",
    "df2.drop(columns=['location'], inplace=True)\n",
    "df.drop(columns=['location'], inplace=True)\n",
    "\n",
    "df2['created_at'] = pd.to_datetime(df2['created_at']).dt.tz_localize(None)\n",
    "\n",
    "df3 = df2.append(df)\n",
    "df3.drop_duplicates(subset=['tweet_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0c5df-b457-4015-bd8e-d6a22a54b5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>776569</th>\n",
       "      <td>911360842528100352</td>\n",
       "      <td>2017-09-22 22:45:31</td>\n",
       "      <td>The reason Frida, the trapped little girl, gri...</td>\n",
       "      <td>186552155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26472</th>\n",
       "      <td>1059683238170542080</td>\n",
       "      <td>2018-11-06 05:45:46</td>\n",
       "      <td>02/14/14: Iâ€™m watching House of Cards (S2) in ...</td>\n",
       "      <td>156334774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54200</th>\n",
       "      <td>1056912735244562434</td>\n",
       "      <td>2018-10-29 14:16:47</td>\n",
       "      <td>0.4, 0.8, 1.1 \\nIf this appears on #OnlyConnec...</td>\n",
       "      <td>310455504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64102</th>\n",
       "      <td>1054783429970137088</td>\n",
       "      <td>2018-10-23 17:15:41</td>\n",
       "      <td>0.4 level earthquake today @NoFrackLancs  Time...</td>\n",
       "      <td>4331730273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106104</th>\n",
       "      <td>1052907078615031808</td>\n",
       "      <td>2018-10-18 12:59:44</td>\n",
       "      <td>074 // earthquake // #100daysofascent #100dayc...</td>\n",
       "      <td>23904102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514569</th>\n",
       "      <td>1052127631221514241</td>\n",
       "      <td>2018-10-16 09:22:29</td>\n",
       "      <td>ã€Œãƒ‰ãƒ¼ãƒ³ï¼ã€ã¨éŸ³ãŒã—ãŸã ã‘ã§ä½•ã‹ã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸã‘ã©ã€æœ€è¿‘å¤šã„ã‚‰ã—ã„â€¦\\nå¤§åœ°éœ‡ã®å‰å…†ã¨ã‹...</td>\n",
       "      <td>550738293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514660</th>\n",
       "      <td>1061534708427706369</td>\n",
       "      <td>2018-11-11 08:22:51</td>\n",
       "      <td>ã“ã®é ƒã€ã¾ãŸåœ°éœ‡ãŒå¤šã„â€¦ã€‚\\nåœ°éœ‡æƒ…å ± - Yahoo!å¤©æ°—ãƒ»ç½å®³ https://t.co...</td>\n",
       "      <td>110049763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515815</th>\n",
       "      <td>1058274420068741120</td>\n",
       "      <td>2018-11-02 08:27:38</td>\n",
       "      <td>ã‚«ãƒ©ã‚¹ãŒé¨’ãŒã—ã‹ã£ãŸã®ã¨ã€å®¶é³´ã‚ŠãŒã‚ã£ãŸã®ã¯ã“ã‚Œã‹ãªï¼Ÿ\\nåœ°éœ‡æƒ…å ± - Yahoo!å¤©æ°—ãƒ»ç½...</td>\n",
       "      <td>2966046025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13516249</th>\n",
       "      <td>1058266760590254080</td>\n",
       "      <td>2018-11-02 07:57:12</td>\n",
       "      <td>é«˜çŸ¥å¸‚å†…æºã‚ŒãŸã­ã€å’Œæ­Œå±±ã®æ–¹ãŒéœ‡æºã¿ãŸã„ã€‚#åœ°éœ‡ #å’Œæ­Œå±± #éœ‡åº¦4 https://t.c...</td>\n",
       "      <td>198874833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517159</th>\n",
       "      <td>884608773515395074</td>\n",
       "      <td>2017-07-11 03:02:21</td>\n",
       "      <td>é¹¿å…å³¶æ¹¾ã§åœ°éœ‡ç™ºç”Ÿï¼ˆ2017å¹´7æœˆ11æ—¥ 11æ™‚56åˆ†ï¼‰æœ€å¤§éœ‡åº¦5å¼· https://t.c...</td>\n",
       "      <td>237587677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18653 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tweet_id          created_at  \\\n",
       "776569     911360842528100352 2017-09-22 22:45:31   \n",
       "26472     1059683238170542080 2018-11-06 05:45:46   \n",
       "54200     1056912735244562434 2018-10-29 14:16:47   \n",
       "64102     1054783429970137088 2018-10-23 17:15:41   \n",
       "106104    1052907078615031808 2018-10-18 12:59:44   \n",
       "...                       ...                 ...   \n",
       "13514569  1052127631221514241 2018-10-16 09:22:29   \n",
       "13514660  1061534708427706369 2018-11-11 08:22:51   \n",
       "13515815  1058274420068741120 2018-11-02 08:27:38   \n",
       "13516249  1058266760590254080 2018-11-02 07:57:12   \n",
       "13517159   884608773515395074 2017-07-11 03:02:21   \n",
       "\n",
       "                                                       text   author_id  \\\n",
       "776569    The reason Frida, the trapped little girl, gri...   186552155   \n",
       "26472     02/14/14: Iâ€™m watching House of Cards (S2) in ...   156334774   \n",
       "54200     0.4, 0.8, 1.1 \\nIf this appears on #OnlyConnec...   310455504   \n",
       "64102     0.4 level earthquake today @NoFrackLancs  Time...  4331730273   \n",
       "106104    074 // earthquake // #100daysofascent #100dayc...    23904102   \n",
       "...                                                     ...         ...   \n",
       "13514569  ã€Œãƒ‰ãƒ¼ãƒ³ï¼ã€ã¨éŸ³ãŒã—ãŸã ã‘ã§ä½•ã‹ã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸã‘ã©ã€æœ€è¿‘å¤šã„ã‚‰ã—ã„â€¦\\nå¤§åœ°éœ‡ã®å‰å…†ã¨ã‹...   550738293   \n",
       "13514660  ã“ã®é ƒã€ã¾ãŸåœ°éœ‡ãŒå¤šã„â€¦ã€‚\\nåœ°éœ‡æƒ…å ± - Yahoo!å¤©æ°—ãƒ»ç½å®³ https://t.co...   110049763   \n",
       "13515815  ã‚«ãƒ©ã‚¹ãŒé¨’ãŒã—ã‹ã£ãŸã®ã¨ã€å®¶é³´ã‚ŠãŒã‚ã£ãŸã®ã¯ã“ã‚Œã‹ãªï¼Ÿ\\nåœ°éœ‡æƒ…å ± - Yahoo!å¤©æ°—ãƒ»ç½...  2966046025   \n",
       "13516249  é«˜çŸ¥å¸‚å†…æºã‚ŒãŸã­ã€å’Œæ­Œå±±ã®æ–¹ãŒéœ‡æºã¿ãŸã„ã€‚#åœ°éœ‡ #å’Œæ­Œå±± #éœ‡åº¦4 https://t.c...   198874833   \n",
       "13517159  é¹¿å…å³¶æ¹¾ã§åœ°éœ‡ç™ºç”Ÿï¼ˆ2017å¹´7æœˆ11æ—¥ 11æ™‚56åˆ†ï¼‰æœ€å¤§éœ‡åº¦5å¼· https://t.c...   237587677   \n",
       "\n",
       "         username  name  \n",
       "776569        NaN  jeff  \n",
       "26472         NaN   NaN  \n",
       "54200         NaN   NaN  \n",
       "64102         NaN   NaN  \n",
       "106104        NaN   NaN  \n",
       "...           ...   ...  \n",
       "13514569      NaN   NaN  \n",
       "13514660      NaN   NaN  \n",
       "13515815      NaN   NaN  \n",
       "13516249      NaN   NaN  \n",
       "13517159      NaN   NaN  \n",
       "\n",
       "[18653 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan again, on column username\n",
    "df3[df3['username'].isna()] # significantly less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26caf8d1-22be-492f-849c-b00882d54dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('temp_df3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12c408-19bd-4c66-bfd9-f7cd198631ea",
   "metadata": {},
   "source": [
    "## Remove Bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e93c92-18d0-45fb-b798-c47b1fc7d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"temp_df3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83205ce3-88bc-43ac-a0fd-f1a68ce48189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with removing all users where username contains 'bot' or 'quake'\n",
    "remove = ['quake', 'bot']\n",
    "dw = df[~df.username.str.contains('|'.join(remove), case=False, na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23c8ebaa-e86c-45c1-b8f5-4a67f3b55093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove users which posted more tweets than certain threshhold\n",
    "post_counts = dw.username.value_counts()\n",
    "lst_user = post_counts.index.tolist()\n",
    "lst_count = post_counts.tolist()\n",
    "\n",
    "post_counts = pd.DataFrame(lst_user).rename(columns={0: 'username'})\n",
    "post_counts['value'] = lst_count\n",
    "\n",
    "\n",
    "bots = post_counts.loc[post_counts['value'] > 100].sort_values(by=['value'])\n",
    "bots = bots.username.tolist()\n",
    "\n",
    "#dw[~dw.username.str.contains('|'.join(bots), case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25d4660a-6e9b-4a1e-8b32-b0384b070aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dw2 = dw[~dw.username.str.contains('|'.join(bots), case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aba7ecc-da93-4664-a6ec-5bd13999fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.to_sql('twitter', con=engine, if_exists='append', chunksize=1000, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67d47e51-6d59-4c83-a60d-043cfdbc4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw.to_sql('dw_twitter', con=engine, if_exists='append', chunksize=1000, index=False)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f92614-ede1-4042-a143-790a27a773d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out accounts with more or equal to 175 postings\n",
    "df = df.loc[df['value'] > 10].sort_values(by=['value'])\n",
    "lst_bots = df_a.username.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# add -from: operator to each entry in list \n",
    "append_str = '-from:'\n",
    "lst_filter = [append_str + sub for sub in lst_bots]\n",
    "\n",
    "# convert list to a string suitable for the query\n",
    "filter_names_query = ' '.join(lst_filter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
