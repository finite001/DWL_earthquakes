{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "canadian-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the requests library\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mathematical-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")  \n",
    "BEARER_TOKEN = config['BEARER_TOKEN']\n",
    "# path where twitter files will be stored\n",
    "path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "promotional-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query parameters \n",
    "query = \"earthquake -minor, -is:reply -is:retweet\" #-from:username / -is:retweet\n",
    "start_time = \"2021-10-17T00:00:00.000Z\"\n",
    "end_time = \"2021-10-17T23:59:59.000Z\"\n",
    "max_results = \"500\"\n",
    "tweet_fields = \"created_at,author_id,geo\" # geo produes unreliable results. Kept anyway to simulate dirty data\n",
    "user_fields = 'username,location' # location is same as geo\n",
    "file_counter = 0\n",
    "expansions = 'author_id'\n",
    "\n",
    "BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAJY%2BNgEAAAAA5SvyA6cq3jifLadZEWMEiYgUj%2FI%3Dci6sbF0x3Ya5EckuWJ6L7M4RJhptE16APFL9PMnhZPZXulQg0I'\n",
    "\n",
    "# put query parameters in a list\n",
    "query_params = {'query': query,'tweet.fields': tweet_fields, 'user.fields': user_fields,  \\\n",
    "                'start_time': start_time, 'end_time': end_time, 'max_results': max_results,\\\n",
    "                'expansions': expansions}\n",
    "\n",
    "url = \"https://api.twitter.com/2/tweets/search/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "orange-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to fetch data\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# define headers for authorization\n",
    "headers = {\"Authorization\": \"Bearer \" + BEARER_TOKEN}\n",
    "\n",
    "print(\"Starting to fetch data\")\n",
    "\n",
    "lst_tweets = []\n",
    "\n",
    "while True:\n",
    "    # get results according to url and query\n",
    "    response = None\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=query_params)\n",
    "              \n",
    "    if response.status_code != 200:\n",
    "         raise Exception(response.status_code, response.text)\n",
    "    \n",
    "    \n",
    "    # combine data to one\n",
    "    json_response = response.json()\n",
    "    if 'data' in json_response:\n",
    "        lst_tweets = lst_tweets + json_response['data']\n",
    "\n",
    "    break\n",
    "\n",
    "    # check if more data available, if yes continue process\n",
    "    file_counter += 1\n",
    "    if 'meta' in json_response:\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            query_params['next_token'] = json_response['meta']['next_token']\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Fetching next few tweets, next_token: \",query_params['next_token'])\n",
    "            time.sleep(4)\n",
    "        else:\n",
    "            file_counter = 0\n",
    "            del query_params['next_token']\n",
    "            break\n",
    "    else:\n",
    "        file_counter = 0\n",
    "        del query_params['next_token']\n",
    "        break\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convertible-entertainment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# create list of all file names with path\n",
    "file_list = glob.glob(os.path.join(os.getcwd(), \"Data\\\\twitter\", \"*.txt\"))\n",
    "\n",
    "tweets = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        tweets.append(json.load(f))\n",
    "        \n",
    "# create df out of the data\n",
    "df_tweets = pd.DataFrame()\n",
    "df_users = pd.DataFrame()\n",
    "for tweet in tweets:\n",
    "    df_tweets=df_tweets.append(pd.json_normalize(tweet['data']))\n",
    "    df_users=df_users.append(pd.json_normalize(tweet['includes']['users']))\n",
    "    \n",
    "\n",
    "df_users = df_users.rename(columns={'id':'author_id'})\n",
    "df = pd.merge(df_tweets, df_users, on='author_id').drop_duplicates(subset='id').reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "reduced-ozone",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>geo.place_id</th>\n",
       "      <th>geo.coordinates.type</th>\n",
       "      <th>geo.coordinates.coordinates</th>\n",
       "      <th>withheld.copyright</th>\n",
       "      <th>withheld.country_codes_x</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>withheld.country_codes_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-17T23:59:54.000Z</td>\n",
       "      <td>#Earthquake M4.7 CANARY ISLANDS, SPAIN REGION ...</td>\n",
       "      <td>809537352909656064</td>\n",
       "      <td>1449887926985363456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQAlerts</td>\n",
       "      <td>Earthquake Monitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-17T23:58:02.000Z</td>\n",
       "      <td>Moderate magnitude 4.3 #earthquake 24 km north...</td>\n",
       "      <td>809537352909656064</td>\n",
       "      <td>1449887457193963525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQAlerts</td>\n",
       "      <td>Earthquake Monitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-17T23:35:21.000Z</td>\n",
       "      <td>#Earthquake M4.4 Mexico: 82 Km Al Oeste De Chi...</td>\n",
       "      <td>809537352909656064</td>\n",
       "      <td>1449881750532939776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQAlerts</td>\n",
       "      <td>Earthquake Monitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-17T23:12:10.000Z</td>\n",
       "      <td>#Earthquake M4.0 MINAHASA, SULAWESI, INDONESIA...</td>\n",
       "      <td>809537352909656064</td>\n",
       "      <td>1449875917761884164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQAlerts</td>\n",
       "      <td>Earthquake Monitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-17T23:02:48.000Z</td>\n",
       "      <td>#Earthquake M3.6 ISLAND OF HAWAII, HAWAII 4min...</td>\n",
       "      <td>809537352909656064</td>\n",
       "      <td>1449873557748596739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQAlerts</td>\n",
       "      <td>Earthquake Monitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>2021-10-17T00:11:48.000Z</td>\n",
       "      <td>Earthquake kills 3 in Bali, Indonesia, destroy...</td>\n",
       "      <td>2282930023</td>\n",
       "      <td>1449528535132119043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7SealsOfTheEnd</td>\n",
       "      <td>7 Seals Of The End</td>\n",
       "      <td>News &amp; Bible verses USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>2021-10-17T00:08:42.000Z</td>\n",
       "      <td>4.8 Magnitude Earthquake Strikes Indonesia’s B...</td>\n",
       "      <td>367694191</td>\n",
       "      <td>1449527755733753857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ANC_News2</td>\n",
       "      <td>Sanjeev Dev Malik</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>2021-10-17T00:08:00.000Z</td>\n",
       "      <td>Moderate earthquake rocks Bali, killing at lea...</td>\n",
       "      <td>1313407652202975232</td>\n",
       "      <td>1449527580844077059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LindaMi14118735</td>\n",
       "      <td>Linda Miranda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>2021-10-17T00:05:38.000Z</td>\n",
       "      <td>A terrible #earthquake hits #Indonesia, causin...</td>\n",
       "      <td>757114028489580544</td>\n",
       "      <td>1449526984086855681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News_Disaster1</td>\n",
       "      <td>نُذر العذاب nibiru</td>\n",
       "      <td>منتديات البشرى الإسلاميه</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>2021-10-17T00:02:19.000Z</td>\n",
       "      <td>The early 20th century Gaddi Baithak stands ta...</td>\n",
       "      <td>19006707</td>\n",
       "      <td>1449526149948784645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECAatState</td>\n",
       "      <td>Exchange Programs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4958 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at  \\\n",
       "0     2021-10-17T23:59:54.000Z   \n",
       "1     2021-10-17T23:58:02.000Z   \n",
       "2     2021-10-17T23:35:21.000Z   \n",
       "3     2021-10-17T23:12:10.000Z   \n",
       "4     2021-10-17T23:02:48.000Z   \n",
       "...                        ...   \n",
       "4953  2021-10-17T00:11:48.000Z   \n",
       "4954  2021-10-17T00:08:42.000Z   \n",
       "4955  2021-10-17T00:08:00.000Z   \n",
       "4956  2021-10-17T00:05:38.000Z   \n",
       "4957  2021-10-17T00:02:19.000Z   \n",
       "\n",
       "                                                   text            author_id  \\\n",
       "0     #Earthquake M4.7 CANARY ISLANDS, SPAIN REGION ...   809537352909656064   \n",
       "1     Moderate magnitude 4.3 #earthquake 24 km north...   809537352909656064   \n",
       "2     #Earthquake M4.4 Mexico: 82 Km Al Oeste De Chi...   809537352909656064   \n",
       "3     #Earthquake M4.0 MINAHASA, SULAWESI, INDONESIA...   809537352909656064   \n",
       "4     #Earthquake M3.6 ISLAND OF HAWAII, HAWAII 4min...   809537352909656064   \n",
       "...                                                 ...                  ...   \n",
       "4953  Earthquake kills 3 in Bali, Indonesia, destroy...           2282930023   \n",
       "4954  4.8 Magnitude Earthquake Strikes Indonesia’s B...            367694191   \n",
       "4955  Moderate earthquake rocks Bali, killing at lea...  1313407652202975232   \n",
       "4956  A terrible #earthquake hits #Indonesia, causin...   757114028489580544   \n",
       "4957  The early 20th century Gaddi Baithak stands ta...             19006707   \n",
       "\n",
       "                       id geo.place_id geo.coordinates.type  \\\n",
       "0     1449887926985363456          NaN                  NaN   \n",
       "1     1449887457193963525          NaN                  NaN   \n",
       "2     1449881750532939776          NaN                  NaN   \n",
       "3     1449875917761884164          NaN                  NaN   \n",
       "4     1449873557748596739          NaN                  NaN   \n",
       "...                   ...          ...                  ...   \n",
       "4953  1449528535132119043          NaN                  NaN   \n",
       "4954  1449527755733753857          NaN                  NaN   \n",
       "4955  1449527580844077059          NaN                  NaN   \n",
       "4956  1449526984086855681          NaN                  NaN   \n",
       "4957  1449526149948784645          NaN                  NaN   \n",
       "\n",
       "     geo.coordinates.coordinates withheld.copyright withheld.country_codes_x  \\\n",
       "0                            NaN                NaN                      NaN   \n",
       "1                            NaN                NaN                      NaN   \n",
       "2                            NaN                NaN                      NaN   \n",
       "3                            NaN                NaN                      NaN   \n",
       "4                            NaN                NaN                      NaN   \n",
       "...                          ...                ...                      ...   \n",
       "4953                         NaN                NaN                      NaN   \n",
       "4954                         NaN                NaN                      NaN   \n",
       "4955                         NaN                NaN                      NaN   \n",
       "4956                         NaN                NaN                      NaN   \n",
       "4957                         NaN                NaN                      NaN   \n",
       "\n",
       "             username                name                   location  \\\n",
       "0            EQAlerts  Earthquake Monitor                        NaN   \n",
       "1            EQAlerts  Earthquake Monitor                        NaN   \n",
       "2            EQAlerts  Earthquake Monitor                        NaN   \n",
       "3            EQAlerts  Earthquake Monitor                        NaN   \n",
       "4            EQAlerts  Earthquake Monitor                        NaN   \n",
       "...               ...                 ...                        ...   \n",
       "4953   7SealsOfTheEnd  7 Seals Of The End    News & Bible verses USA   \n",
       "4954        ANC_News2   Sanjeev Dev Malik                    Gurgaon   \n",
       "4955  LindaMi14118735       Linda Miranda                        NaN   \n",
       "4956   News_Disaster1  نُذر العذاب nibiru  منتديات البشرى الإسلاميه    \n",
       "4957       ECAatState   Exchange Programs             Washington, DC   \n",
       "\n",
       "     withheld.country_codes_y  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "...                       ...  \n",
       "4953                      NaN  \n",
       "4954                      NaN  \n",
       "4955                      NaN  \n",
       "4956                      NaN  \n",
       "4957                      NaN  \n",
       "\n",
       "[4958 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "retained-string",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create df with usernames and number of postings\n",
    "account_df = df.username.value_counts()\n",
    "lst_a = account_df.index.tolist()\n",
    "lst_v = account_df.tolist()\n",
    "\n",
    "df_a = pd.DataFrame(lst_a).rename(columns={0: 'username'})\n",
    "df_a['value'] = lst_v\n",
    "\n",
    "# filter out accounts with more or equal to 175 postings\n",
    "df_a = df_a.loc[df_a['value'] > 10].sort_values(by=['value'])\n",
    "lst_bots = df_a.username.tolist()\n",
    "\n",
    "# add -from: operator to each entry in list \n",
    "append_str = '-from:'\n",
    "lst_filter = [append_str + sub for sub in lst_bots]\n",
    "\n",
    "# convert list to a string suitable for the query\n",
    "filter_names_query = ' '.join(lst_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arbitrary-conversion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-from:quakeupdates -from:jojo2727 -from:MonitorSismico -from:MyComicalLife -from:news_sokuho_bot -from:DiariosRobot -from:EN_NERV -from:GDACS -from:earthquake_jp -from:EQAlerts -from:j1_quake -from:iSachinSrivstva -from:VolcanoEWS -from:ChileAlertaApp -from:earthb0t -from:sexy_vegetables -from:zishin3255 -from:everyEarthquake -from:MapQuake -from:swap_bot_bash -from:eq_map -from:eq_map_es -from:eq_map_ww -from:SEISMOinfo -from:VegaBajaWx -from:WatchOurCity -from:Keith_Event -from:SismoDetector -from:cvb_223 -from:ExBulletinUk -from:EMSC -from:StoixeioJewelry -from:megamodo -from:earthquakevt -from:QuakeBotter -from:twtaka_jp -from:EarthquakeTw -from:ENSO1998 -from:eq_map_ww2 -from:eq_map_es2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_names_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "prescription-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query parameters \n",
    "query = \"earthquake -minor, -is:reply -is:retweet \" + filter_names_query\n",
    "start_time = \"2020-12-01T00:00:00.000Z\"\n",
    "end_time = \"2020-12-31T23:59:59.000Z\"\n",
    "max_results = \"500\"\n",
    "tweet_fields = \"created_at,author_id,geo\" # geo produes unreliable results. Kept anyway to simulate dirty data\n",
    "user_fields = 'username,location' # location is same as geo\n",
    "place_country = 'JP'\n",
    "file_counter = 0\n",
    "expansions = 'author_id'\n",
    "\n",
    "\n",
    "\n",
    "# put query parameters in a list\n",
    "query_params = {'query': query,'tweet.fields': tweet_fields, 'user.fields': user_fields,  \\\n",
    "                'start_time': start_time, 'end_time': end_time, 'max_results': max_results,\\\n",
    "                'expansions': expansions}\n",
    "\n",
    "url = \"https://api.twitter.com/2/tweets/search/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define headers for authorization\n",
    "headers = {\"Authorization\": \"Bearer \" + BEARER_TOKEN}\n",
    "\n",
    "print(\"Starting to fetch data\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    # get results according to url and query\n",
    "    response = None\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=query_params)\n",
    "              \n",
    "    if response.status_code != 200:\n",
    "         raise Exception(response.status_code, response.text)\n",
    "    \n",
    "    # create json out of result\n",
    "    json_response = response.json()\n",
    "    \n",
    "    # write data into txt\n",
    "    with open(path + \"twitter_file_\" + str(file_counter) + \".txt\",\n",
    "              \"w\") as outfile:\n",
    "        outfile.write(json.dumps(json_response, indent=4))\n",
    "\n",
    "    # check if more data available, if yes continue process\n",
    "    file_counter += 1\n",
    "    if 'meta' in json_response:\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            query_params['next_token'] = json_response['meta']['next_token']\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Fetching next few tweets, next_token: \",query_params['next_token'])\n",
    "            time.sleep(4)\n",
    "        else:\n",
    "            file_counter = 0\n",
    "            break\n",
    "    else:\n",
    "        file_counter = 0\n",
    "        break\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-scroll",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
