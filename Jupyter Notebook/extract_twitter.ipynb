{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comprehensive-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-deposit",
   "metadata": {},
   "source": [
    "### Connection to AWS DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brave-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the connection details for the rds db from .env file\n",
    "config = dotenv_values(\".env\")  \n",
    "HOST_RDS = config['HOST_RDS']\n",
    "DBNAME_RDS = config['DBNAME_RDS']\n",
    "USER_RDS = config['USER_RDS']\n",
    "PASSWORD_RDS = config['PASSWORD_RDS']\n",
    "\n",
    "\n",
    "try: \n",
    "    conn = psycopg2.connect(host=HOST_RDS, dbname=DBNAME_RDS, user=USER_RDS, password=PASSWORD_RDS)\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informational-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not get curser to the Database\")\n",
    "    print(e)\n",
    "    \n",
    "# Auto commit is very important\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desirable-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur.execute(\"DROP TABLE IF EXISTS tweets;\")\n",
    "#cur.execute(\"DROP TABLE IF EXISTS tweets_user;\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS tweets11 (\n",
    "            text text, \n",
    "            author_id bigint,\n",
    "            id bigint,\n",
    "            created_at text);\"\"\")\n",
    "\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS tweets_user11 (\n",
    "            id bigint, \n",
    "            username text, \n",
    "            name text, \n",
    "            location text);\"\"\")\n",
    "\n",
    "table_name_t = 'tweets2'\n",
    "table_name_u = 'tweets_user2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-favorite",
   "metadata": {},
   "source": [
    "### Accessing Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = config['BEARER_TOKEN']\n",
    "\n",
    "# path where twitter files will be stored\n",
    "path = \"Data/twitter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inappropriate-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_QUERY = \"-from:quakeupdates -from:jojo2727 -from:MonitorSismico -from:MyComicalLife -from:news_sokuho_bot -from:DiariosRobot -from:EN_NERV -from:GDACS -from:earthquake_jp -from:EQAlerts -from:j1_quake -from:iSachinSrivstva -from:VolcanoEWS -from:ChileAlertaApp -from:earthb0t -from:sexy_vegetables -from:zishin3255 -from:everyEarthquake -from:MapQuake -from:swap_bot_bash -from:eq_map -from:eq_map_es -from:eq_map_ww -from:SEISMOinfo -from:VegaBajaWx -from:WatchOurCity -from:Keith_Event -from:SismoDetector -from:cvb_223 -from:ExBulletinUk -from:EMSC -from:StoixeioJewelry -from:megamodo -from:earthquakevt -from:QuakeBotter -from:twtaka_jp -from:EarthquakeTw -from:ENSO1998 -from:eq_map_ww2 -from:eq_map_es2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wooden-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2011-01-01T00:00:00.000Z'\n",
    "end_time = \"2011-01-31T23:59:59.000Z\"\n",
    "query = \"earthquake -minor, -is:reply -is:retweet {0}\".format(FILTER_QUERY)\n",
    "max_results = \"500\"\n",
    "tweet_fields = \"created_at,author_id\"\n",
    "user_fields = 'username,location'\n",
    "expansions = 'author_id'\n",
    "query_params = {'query': query, 'tweet.fields': tweet_fields, 'user.fields': user_fields, \\\n",
    "                'start_time': start_time, 'end_time': end_time, 'max_results': max_results, \\\n",
    "                'expansions': expansions}\n",
    "url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "headers = {\"Authorization\": \"Bearer \" + BEARER_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "painful-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "users = []\n",
    "while True:\n",
    "    # get results according to url and query\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=query_params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "\n",
    "    # combine data to one\n",
    "    json_response = response.json()\n",
    "    if 'data' in json_response:\n",
    "        tweets = tweets + json_response['data']\n",
    "        users = users + json_response['includes']['users']\n",
    "\n",
    "    # check if more data available, if yes continue process\n",
    "    if 'meta' in json_response:\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            query_params['next_token'] = json_response['meta']['next_token']\n",
    "            next_token = json_response['meta']['next_token']\n",
    "          #  logging.info(\"Fetching next few tweets, next_token: \", query_params['next_token'])\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            if 'next_token' in query_params:\n",
    "                del query_params['next_token']\n",
    "            break\n",
    "    else:\n",
    "        if 'next_token' in query_params:\n",
    "            del query_params['next_token']\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "domestic-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add location to all users, empty string if element does not exist (to insert data into table)\n",
    "# for item in users:\n",
    "#     if 'location' in item:\n",
    "#         pass\n",
    "#     else:\n",
    "#         item['location'] = \"\"\n",
    "        \n",
    "# # create iterators\n",
    "#iter_tweets = iter(tweets)\n",
    "# iter_users = iter(users)\n",
    "\n",
    "# insert tweets\n",
    "psycopg2.extras.execute_batch(cur, \"\"\"INSERT INTO tweets11 VALUES(\n",
    "%(text)s,\n",
    "%(author_id)s,\n",
    "%(id)s,\n",
    "%(created_at)s\n",
    ");\"\"\",iter_tweets)\n",
    "\n",
    "# # insert users\n",
    "# psycopg2.extras.execute_batch(cur, \"\"\"INSERT INTO tweets_user11 VALUES(\n",
    "# %(id)s,\n",
    "# %(username)s,\n",
    "# %(name)s,\n",
    "# %(location)s\n",
    "# );\"\"\",iter_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b72b6ab0-fa20-4a62-81ff-144048d38040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '243117582',\n",
       " 'created_at': '2011-03-11T14:13:32.000Z',\n",
       " 'text': 'All for Japan! Prayers,hope,love for Japan and the people affected by the earthquake amen!',\n",
       " 'id': '46212161105707008'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unauthorized-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"2011-09-30-2011-07-24.txt\",\n",
    "          \"w\") as outfile:\n",
    "    outfile.write(json.dumps(users, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assured-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
